{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain\n",
    "\n",
    "Goal: Build a fragrance recomendation system using Langchain, OPENAI, DocArray and RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "perfume_df = pd.read_csv('data/final_perfume_data.csv', encoding='unicode_escape')\n",
    "perfume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain packages\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# LLM Chain - simplest chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a pefume with the following notes: {notes}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "notes = \"floral, citrus, musk\"\n",
    "chain.run(notes)\n",
    "\n",
    "\n",
    "## Sequential Chain - works well for multiple inputs and outputs\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1: give notes a name\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a pefume with the following notes: {notes}\",\n",
    ")\n",
    "\n",
    "# Chain 1: input = notes, output = perfume name\n",
    "chain1 = LLMChain(llm=llm, prompt=first_prompt, output_key=\"perfume_name\")\n",
    "\n",
    "# prompt template 2: give name a description\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 word description for a perfume with the following name: {perfume_name}\",\n",
    ")\n",
    "\n",
    "# Chain 2: input = perfume name, output = perfume description\n",
    "chain2 = LLMChain(llm=llm, prompt=second_prompt, output_key=\"perfume_description\")\n",
    "#prompt template 3: convert the description to a tagline\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a catchy 8 word tagline for a perfume with the following description: {perfume_description}\",\n",
    ")\n",
    "\n",
    "# Chain 3: input = perfume description, output = perfume tagline\n",
    "chain3 = LLMChain(llm=llm, prompt=third_prompt, output_key=\"perfume_tagline\")\n",
    "# prompt template 4: similar fragrance to notes\n",
    "fifth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"List 3 other perfumes with the following notes: {notes}\",\n",
    ")\n",
    "\n",
    "# Chain 4: input = notes, output = similar fragrances\n",
    "chain4 = LLMChain(llm=llm, prompt=fifth_prompt, output_key=\"similar_fragrances\")\n",
    "# overall chain: input= notes\n",
    "# and output = perfume name, description, tagline, similar fragrances\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2, chain3, chain4],\n",
    "    input_variables=[\"notes\"],\n",
    "    output_variables=[\"perfume_name\", \"perfume_description\", \"perfume_tagline\", \"similar_fragrances\"],\n",
    "    verbose=True\n",
    ")\n",
    "notes =perfume_df['Notes'][5]\n",
    "overall_chain(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q&A with RAG - build this part live\n",
    "\n",
    "# imports OWN CELL\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings # chat completion model and embeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter # split text into characters\n",
    "from langchain.document_loaders import CSVLoader # load data from a csv file - from langchain_community\n",
    "from langchain.vectorstores import DocArrayInMemorySearch #vectorstore, in memory, no need to connect to an external vectorestore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.display import display, Markdown  # display markdown in jupyter notebook\n",
    "\n",
    "# This section - OWN CELL\n",
    "# create a document loader - each doc represents a perfume\n",
    "documents = 'data/final_perfume_data.csv'\n",
    "loader = CSVLoader(file_path=documents, encoding='unicode_escape').load()\n",
    "\n",
    "# split text into characters\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(loader)\n",
    "\n",
    "# create embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectors = embeddings.embed_query(\"floral, citrus, musk\") # example embedding\n",
    "print(len(vectors)) #print the length of the embedding for the example \n",
    "print(vectors[:5]) #print the numerical representation of the first 5 elements of the embedding\n",
    "\n",
    "# create vectorstore\n",
    "vectorstore_db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "# Similarity search (OWN CELL)\n",
    "\n",
    "query = \"please list similar fragrances to chanel no 5.\"\n",
    "docs = vectorstore_db.similarity_search(query)\n",
    "\n",
    "results = \"\".join([docs[i].page_content for i in range(len(docs))])\n",
    "print(results)\n",
    "\n",
    "\n",
    "# RAG - OWN CELL\n",
    "# Retriever\n",
    "# create a retriever\n",
    "retriever = vectorstore_db.as_retriever()\n",
    "\n",
    "# create a chat model\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "# join docs in a variable\n",
    "qdocs = \"\\n\\n\".join([docs[i].page_content for i in range(len(docs))])\n",
    "\n",
    "# def qdocs(docs):\n",
    "#     return \"\\n\\n\".join([docs[i].page_content for i in range(len(docs))])\n",
    "\n",
    "# get a response\n",
    "response = llm.invoke(f\"{qdocs} Question: {query}\")\n",
    "\n",
    "# display the response\n",
    "display(Markdown(response.content))\n",
    "\n",
    "# def display_markdown(content):\n",
    "#     display(Markdown(content))\n",
    "#     return content\n",
    "\n",
    "# OWN CELL\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Return the answer in a markdown table with the name, brand and image.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | qdocs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | display_markdown\n",
    ")\n",
    "\n",
    "# rag_chain.invoke(\"what are the notes of Freeworld Parfum?\")\n",
    "rag_chain.invoke(\"List 3 similar fragrances to Circus Fantasy.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
